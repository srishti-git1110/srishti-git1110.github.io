<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><script type=text/javascript src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[WIP] CPU, GPU and stuff! | Srishti Gureja</title><meta name=keywords content="Computer Architecture,Optimization,Parallel Processing"><meta name=description content="Some beginner stuff!
Core, Microprocessor/Processor, Chip
&ldquo;A chip&rdquo; is the physical semiconductor chip; it&rsquo;s &ldquo;a physical integrated circuit&rdquo; comprised of transistors, resistors, and capacitors.
A processor (here, think of CPU, the central &ldquo;processing&rdquo; unit) is a digital circuit that&rsquo;s implemented on a single or a few chips. Now, the term micro is appended to the beginning of processors to refer to the fact that it takes a single or a very few chips to implement a microprocessor. But this is more of a definition. In the context/scope of this post, consider 1 microprocessor = 1 chip."><meta name=author content><link rel=canonical href=http://localhost:1313/blog/hardware-primer/><link crossorigin=anonymous href=/assets/css/stylesheet.b26ba54a60d00ea06fda6b711f3da6382e5fe3a6fae7b4cc58bdc38f1f26bddc.css integrity="sha256-smulSmDQDqBv2mtxHz2mOC5f46b657TMWL3Djx8mvdw=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/favicon-32x32.png><link rel=apple-touch-icon href=http://localhost:1313/apple-touch-icon.png><link rel=mask-icon href=http://localhost:1313/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/blog/hardware-primer/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="[WIP] CPU, GPU and stuff!"><meta property="og:description" content="Some beginner stuff!
Core, Microprocessor/Processor, Chip
&ldquo;A chip&rdquo; is the physical semiconductor chip; it&rsquo;s &ldquo;a physical integrated circuit&rdquo; comprised of transistors, resistors, and capacitors.
A processor (here, think of CPU, the central &ldquo;processing&rdquo; unit) is a digital circuit that&rsquo;s implemented on a single or a few chips. Now, the term micro is appended to the beginning of processors to refer to the fact that it takes a single or a very few chips to implement a microprocessor. But this is more of a definition. In the context/scope of this post, consider 1 microprocessor = 1 chip."><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/blog/hardware-primer/"><meta property="article:section" content="blog"><meta property="article:published_time" content="2025-11-30T00:00:00+00:00"><meta property="article:modified_time" content="2025-11-30T00:00:00+00:00"><meta property="og:site_name" content="Srishti Gureja"><meta name=twitter:card content="summary"><meta name=twitter:title content="[WIP] CPU, GPU and stuff!"><meta name=twitter:description content="Some beginner stuff!
Core, Microprocessor/Processor, Chip
&ldquo;A chip&rdquo; is the physical semiconductor chip; it&rsquo;s &ldquo;a physical integrated circuit&rdquo; comprised of transistors, resistors, and capacitors.
A processor (here, think of CPU, the central &ldquo;processing&rdquo; unit) is a digital circuit that&rsquo;s implemented on a single or a few chips. Now, the term micro is appended to the beginning of processors to refer to the fact that it takes a single or a very few chips to implement a microprocessor. But this is more of a definition. In the context/scope of this post, consider 1 microprocessor = 1 chip."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blogs","item":"http://localhost:1313/blog/"},{"@type":"ListItem","position":2,"name":"[WIP] CPU, GPU and stuff!","item":"http://localhost:1313/blog/hardware-primer/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[WIP] CPU, GPU and stuff!","name":"[WIP] CPU, GPU and stuff!","description":"Some beginner stuff!\nCore, Microprocessor/Processor, Chip \u0026ldquo;A chip\u0026rdquo; is the physical semiconductor chip; it\u0026rsquo;s \u0026ldquo;a physical integrated circuit\u0026rdquo; comprised of transistors, resistors, and capacitors.\nA processor (here, think of CPU, the central \u0026ldquo;processing\u0026rdquo; unit) is a digital circuit that\u0026rsquo;s implemented on a single or a few chips. Now, the term micro is appended to the beginning of processors to refer to the fact that it takes a single or a very few chips to implement a microprocessor. But this is more of a definition. In the context/scope of this post, consider 1 microprocessor = 1 chip.\n","keywords":["Computer Architecture, Optimization, Parallel Processing"],"articleBody":"Some beginner stuff!\nCore, Microprocessor/Processor, Chip ‚ÄúA chip‚Äù is the physical semiconductor chip; it‚Äôs ‚Äúa physical integrated circuit‚Äù comprised of transistors, resistors, and capacitors.\nA processor (here, think of CPU, the central ‚Äúprocessing‚Äù unit) is a digital circuit that‚Äôs implemented on a single or a few chips. Now, the term micro is appended to the beginning of processors to refer to the fact that it takes a single or a very few chips to implement a microprocessor. But this is more of a definition. In the context/scope of this post, consider 1 microprocessor = 1 chip.\nThe modern day computer is powered by processors of different types - CPUs, GPUs etc. I have also read the term processor chip being used, the meaning of which should be clear now.\nNow, here‚Äôs the thing: In older days, 1 processor used to mean 1 processing unit (single CPU based microprocessor) which changed around the year 2000 when microprocessors with more than one processing unit/CPU were introduced. Those are what are called as multi-core processors (The last section touches upon why this shift happened in the hardware industry).\nHence, a CPU ‚Äúcore‚Äù is basically a single processing unit within a processor chip that is capable of running instructions independently; and hence the modern day microprocessor with several cores is essentially a parallel processor benefitting from software that leverages parallel programming paradigms. Read that again until the terms Core, Microprocessor/Processor, Chip and the distinctions and synonymities between them are clear.\nüëâ If you google intel core i9 processor, the table there has a column # of ‚Äúcores‚Äù.\nClock rate By definition, it‚Äôs the number of clock cycles per second. The term clock cycle is what actually needs an explanation: it‚Äôs the time taken (for the internal oscillator) to complete one electric signal. Now, an instruction (which could be anything like adding two numbers or writing data to the memory) can be completed by the CPU within one or more than one clock cycles and hence the clock rate is significant in determining the number of instructions that the CPU can finish in a second.\nImportantly, a higher clock rate doesn‚Äôt always imply a faster CPU because other factors like the CPU architecture etc. also play a role. But keeping other things constant, a higher clock rate does imply a faster CPU and we‚Äôll keep that notion in mind for the rest of this blog at least.\nLet‚Äôs see an example demonstrating why the clock rate matters. Consider a machine with the following specs:\n#Processor chips: 2 #cores per chip: 9 Clock rate of a core: 2.9 Ghz floating point unit ops: 8 double precision ops (including FMA, fused multiply and add) per core per cycle If we now want to calculate the peak number of floating point ops that can be performed by this machine per cycle, we‚Äôd do:\n2.9 x 2 x 9 x 16 = 835 GFLOPS\nIf we could hence build a machine with a higher clock rate, that directly translates to better ‚Äúpeak‚Äù performance. Utilizing it as much as possible depends on one‚Äôs skills. :)\nTypes of Random Access Memory (RAM) Before proceeding to study the processor architectures, it‚Äôs worth discussing in brief two types of RAM - Static RAM (SRAM) and Dynamic RAM (DRAM).\n[RAM is just a type of memory from which any data, regardless of its position, can be accessed in the same time using its address. The abstract/conceptual way to think about memory, be it on-chip or off-chip, is as an array of bits each having its own address that can be used to access it.]\nThe short story is that the hardware components used to build these two types of RAM differ from each other which makes SRAM way faster but also bulkier and way more expensive as compared to DRAM.\nSRAM - The design is such that a single cell requires 6 transistors ‚Äì 6 transistors are required to store a bit which makes SRAM bulky but since these transistors hold the charge permanently as long as power is supplied, SRAM doesn‚Äôt need to be refreshed making it faster. Owing to its design again, a lot of chip area is required to store one bit making it expensive.\nDRAM - DRAM only requires one capacitor and one transistor to store a bit where the capacitor stores the charge representing the bit (0 or 1). Over time, this charge leaks and so DRAM cannot hold the data permanently even through the time when power is supplied requiring continous refreshes to prevent data loss. This makes DRAM slower but cheaper as less area and transistors are dedicated to storing a bit.\nWhy it‚Äôs important to know the distinction between these two is simply because modern day processors leverage various memories of which some are designed as DRAM and some as SRAM. For instance, the main memory (RAM as we call it) is actually DRAM (and not SRAM because üí∏).\nProcessor Architectures Let us now look into the architectures of the CPU and the GPU, and try to make sense of why the CPU is called a latency device and the GPU, a throughput device.\nCPU Let us first look at what a chip with 4 cores looks like:\nImage source A slight but important correction to note here is that while according to the figure above, the DRAM (sometimes simply referred to as RAM or system memory) appears to be located on the chip, it‚Äôs not acutally the case. The DRAM is a separate hardware entity that‚Äôs mounted on the motherboard.\nNext, pay attention to how the chip area is divided among the different components. Note also the multiple levels of cache memories present on the chip (purple and blue) ‚Äì they help to reduce the latency by decreasing the amount of high latency memory (DRAM) accesses.\nNow let‚Äôs zoom into a single core:\n// figure\nA few main components are shown in the core above:\nA few very powerful ALUs (Arithmetic Logic Units): A few of them are present on each core and it‚Äôs where the actual computation happens. Each ALU in itself is very powerful and capable of completing a computation in a very few clock cycles; and hence follows the low latency design philosophy.\nA Control Unit (CU): A major area is occupied by this component as its two main functions help greatly in reducing the latency - branch prediction and data forwarding. A larger CU again serves the low latency design.\nCaches: A significant (i.e. significantly large when compared to GPU cache size) portion of each core is dedicated to on-chip caches as caches reduce the latency by reducing the amount of RAM accesses required. DRAM accesses are large latency accesses in that they take a lot more clock cycles to finish as compared to on-chip caches and hence cause stalling if the processor needs to access the DRAM frequently.\nA bit about caches Temporal Locality: Let‚Äôs say the processor needs acess to a datum value that‚Äôs not in any of the caches yet and hence needs to be fetched from the memory. When this datum is fetched from the memory for the processor to be able to use it, it‚Äôs also loaded into the cache. This serves what‚Äôs known as ‚Äútemporal locality‚Äù which, in essence, means that the processor has the tendency to use the same datum value again in near future and hence it‚Äôs valuable to store it in the cache.\nSpatial Locality: The way data is loaded in the cache(s) is in the granularity of what‚Äôs knows as cache lines. This means it‚Äôs not just one particular datum that‚Äôs loaded in the cache, but a whole ‚Äúcache line‚Äù of contiguous data values is loaded along with it. So, let‚Äôs say the cache line size for a particular processor is 128 bytes (which is the case for my machine - Apple M4), that‚Äôs equivalent to loading a line of 4 fp32 floats. Consequently, cache eviction, which refers to removing certain data from the cache in order to feed in new data, also happens in cache lines. The question here is why we would do this. It‚Äôs because this serves ‚Äúspatial locality‚Äù which states that the processor is likely to use in future the data values near the current datum it‚Äôs required to use.\nLet‚Äôs see this in action:\nUnderstanding caches and the way they work is really important for performance engineering. One example of that is here.\nSIMD units: GPU From the same source, here‚Äôs what a GPU chip looks like:\nAs can be seen, the major chip area is now occupied by the green boxes which are the components where the computation takes place. But what‚Äôs also worth noting is that each green box is now much more smaller than 1 single ALU in the CPU core ‚Äì this actually reflects the real scenario that a single of these units on the GPU is much much less powerful than a single ALU and hence has a much longer latency.\nThe L1 caches and the control occupy much lesser chip area.\nMemory Bus Memory Bandwidth Why can‚Äôt CPUs just have a higher memory bandwidth? Why parallelization? Until 2004, Moore‚Äôs law, that states that the number of transistors on an integrated circuit doubles roughly every two years, was full in action. This along with Dennard scaling led to faster chips, with increased clock rates at a constant power and cost requirement, coming in about every 18 months or so. And hence, optimization of sequential programs, though useful wasn‚Äôt really the focus as every two years or so, the new hardware guaranteed better performance for the exact same (unoptimized sequential code) anyways.\nWhat changed then? While Moore‚Äôs law kept allowing for more transistors per chip (smaller in size and more in number), Dennard scaling broke. Meaning we could no longer get increased clock rates on a single core due to issues like charge leakage, heat dissipation etc. and hence hardware engineers couldn‚Äôt fit more transistors onto a single core which further meant programmers could no longer depend on the hardware in order to get speedups to their programs. What the hardware industry then transitioned to is the multicore cpu chips we know today. This required the programmers to write parallel code so as to be able to continue enjoying speedups moving beyond a single cpu core. In short, moving forward the only way to get better performance is parallelism as from a hardware pove, single core performance gains have already maxed out.\n","wordCount":"1750","inLanguage":"en","datePublished":"2025-11-30T00:00:00Z","dateModified":"2025-11-30T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/blog/hardware-primer/"},"publisher":{"@type":"Organization","name":"Srishti Gureja","logo":{"@type":"ImageObject","url":"http://localhost:1313/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Srishti Gureja (Alt + H)">Srishti Gureja</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/code/ title=code><span>code</span></a></li><li><a href=http://localhost:1313/blog/ title=blog><span>blog</span></a></li><li><a href=http://localhost:1313/talks/ title=talks><span>talks</span></a></li><li><a href=http://localhost:1313/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;¬ª&nbsp;<a href=http://localhost:1313/blog/>Blogs</a></div><h1 class="post-title entry-hint-parent">[WIP] CPU, GPU and stuff!</h1><div class=post-meta><span title='2025-11-30 00:00:00 +0000 UTC'>November 30, 2025</span></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#core-microprocessorprocessor-chip>Core, Microprocessor/Processor, Chip</a></li><li><a href=#clock-rate>Clock rate</a></li><li><a href=#types-of-random-access-memory-ram>Types of Random Access Memory (RAM)</a></li><li><a href=#processor-architectures>Processor Architectures</a><ul><li><a href=#cpu>CPU</a></li><li><a href=#gpu>GPU</a></li></ul></li><li><a href=#memory-bus>Memory Bus</a></li><li><a href=#memory-bandwidth>Memory Bandwidth</a><ul><li><a href=#why-cant-cpus-just-have-a-higher-memory-bandwidth>Why can&rsquo;t CPUs just have a higher memory bandwidth?</a></li></ul></li><li><a href=#why-parallelization>Why parallelization?</a></li></ul></nav></div></details></div><div class=post-content><p>Some beginner stuff!</p><h2 id=core-microprocessorprocessor-chip>Core, Microprocessor/Processor, Chip<a hidden class=anchor aria-hidden=true href=#core-microprocessorprocessor-chip>#</a></h2><p>&ldquo;A chip&rdquo; is the physical semiconductor chip; it&rsquo;s &ldquo;a physical integrated circuit&rdquo; comprised of transistors, resistors, and capacitors.</p><p>A processor (here, think of CPU, the central &ldquo;processing&rdquo; unit) is a digital circuit that&rsquo;s implemented on a single or a few chips. Now, the term micro is appended to the beginning of processors to refer to the fact that it takes a single or a very few chips to implement a microprocessor. But this is more of a definition. In the context/scope of this post, consider 1 microprocessor = 1 chip.</p><p>The modern day computer is powered by processors of different types - CPUs, GPUs etc. I have also read the term processor chip being used, the meaning of which should be clear now.</p><p>Now, here&rsquo;s the thing: In older days, 1 processor used to mean 1 processing unit (single CPU based microprocessor) which changed around the year 2000 when microprocessors with more than one processing unit/CPU were introduced. Those are what are called as multi-core processors (The last section touches upon why this shift happened in the hardware industry).</p><p>Hence, a CPU &ldquo;core&rdquo; is basically a single processing unit within a processor chip that is capable of running instructions independently; and hence the modern day microprocessor with several cores is essentially a parallel processor benefitting from software that leverages parallel programming paradigms. Read that again until the terms Core, Microprocessor/Processor, Chip and the distinctions and synonymities between them are clear.</p><p>üëâ If you google <a href=https://www.intel.com/content/www/us/en/products/details/processors/core/i9/products.html>intel core i9 processor</a>, the table there has a column # of &ldquo;cores&rdquo;.</p><h2 id=clock-rate>Clock rate<a hidden class=anchor aria-hidden=true href=#clock-rate>#</a></h2><p>By definition, it&rsquo;s the number of clock cycles per second. The term clock cycle is what actually needs an explanation: it&rsquo;s the time taken (for the internal oscillator) to complete one electric signal. Now, an instruction (which could be anything like adding two numbers or writing data to the memory) can be completed by the CPU within one or more than one clock cycles and hence the clock rate is significant in determining the number of instructions that the CPU can finish in a second.</p><p>Importantly, a higher clock rate doesn&rsquo;t always imply a faster CPU because other factors like the CPU architecture etc. also play a role. But keeping other things constant, a higher clock rate does imply a faster CPU and we&rsquo;ll keep that notion in mind for the rest of this blog at least.</p><p>Let&rsquo;s see an example demonstrating why the clock rate matters. Consider a machine with the following specs:</p><ul><li>#Processor chips: 2</li><li>#cores per chip: 9</li><li>Clock rate of a core: 2.9 Ghz</li><li>floating point unit ops: 8 double precision ops (including FMA, fused multiply and add) per core per cycle</li></ul><p>If we now want to calculate the peak number of floating point ops that can be performed by this machine per cycle, we&rsquo;d do:</p><p>2.9 x 2 x 9 x 16 = 835 GFLOPS</p><p>If we could hence build a machine with a higher clock rate, that directly translates to better &ldquo;peak&rdquo; performance. Utilizing it as much as possible depends on one&rsquo;s skills. :)</p><h2 id=types-of-random-access-memory-ram>Types of Random Access Memory (RAM)<a hidden class=anchor aria-hidden=true href=#types-of-random-access-memory-ram>#</a></h2><p>Before proceeding to study the processor architectures, it&rsquo;s worth discussing in brief two types of RAM - Static RAM (SRAM) and Dynamic RAM (DRAM).</p><p>[RAM is just a type of memory from which any data, regardless of its position, can be accessed in the same time using its address. The abstract/conceptual way to think about memory, be it on-chip or off-chip, is as an array of bits each having its own address that can be used to access it.]</p><p>The short story is that the hardware components used to build these two types of RAM differ from each other which makes SRAM way faster but also bulkier and way more expensive as compared to DRAM.</p><ol><li><p><strong>SRAM</strong> - The design is such that a single cell requires 6 transistors &ndash; 6 transistors are required to store a bit which makes SRAM bulky but since these transistors hold the charge permanently as long as power is supplied, SRAM doesn&rsquo;t need to be refreshed making it faster. Owing to its design again, a lot of chip area is required to store one bit making it expensive.</p></li><li><p><strong>DRAM</strong> - DRAM only requires one capacitor and one transistor to store a bit where the capacitor stores the charge representing the bit (0 or 1). Over time, this charge leaks and so DRAM cannot hold the data permanently even through the time when power is supplied requiring continous refreshes to prevent data loss. This makes DRAM slower but cheaper as less area and transistors are dedicated to storing a bit.</p></li></ol><p>Why it&rsquo;s important to know the distinction between these two is simply because modern day processors leverage various memories of which some are designed as DRAM and some as SRAM. For instance, the main memory (RAM as we call it) is actually DRAM (and not SRAM because üí∏).</p><h2 id=processor-architectures>Processor Architectures<a hidden class=anchor aria-hidden=true href=#processor-architectures>#</a></h2><p>Let us now look into the architectures of the CPU and the GPU, and try to make sense of why the CPU is called a latency device and the GPU, a throughput device.</p><h3 id=cpu>CPU<a hidden class=anchor aria-hidden=true href=#cpu>#</a></h3><p>Let us first look at what a chip with 4 cores looks like:</p><p><img loading=lazy src=cpu-chip.png#center alt="A CPU chip">
<em><a href=https://cvw.cac.cornell.edu/gpu-architecture/gpu-characteristics/design>Image source</a></em>
A slight but important correction to note here is that while according to the figure above, the DRAM (sometimes simply referred to as RAM or system memory) appears to be located on the chip, it&rsquo;s not acutally the case. The DRAM is a separate hardware entity that&rsquo;s mounted on the motherboard.</p><p>Next, pay attention to <em>how</em> the chip area is divided among the different components. Note also the multiple levels of cache memories present on the chip (purple and blue) &ndash; they help to reduce the latency by decreasing the amount of high latency memory (DRAM) accesses.</p><p>Now let&rsquo;s zoom into a single core:</p><p>// figure</p><p>A few main components are shown in the core above:</p><ol><li><p>A few very powerful ALUs (Arithmetic Logic Units): A few of them are present on each core and it&rsquo;s where the actual computation happens. Each ALU in itself is very powerful and capable of completing a computation in a very few clock cycles; and hence follows the low latency design philosophy.</p></li><li><p>A Control Unit (CU): A major area is occupied by this component as its two main functions help greatly in reducing the latency - branch prediction and data forwarding. A larger CU again serves the low latency design.</p></li><li><p>Caches: A significant (i.e. significantly large when compared to GPU cache size) portion of each core is dedicated to on-chip caches as caches reduce the latency by reducing the amount of RAM accesses required. DRAM accesses are large latency accesses in that they take a lot more clock cycles to finish as compared to on-chip caches and hence cause stalling if the processor needs to access the DRAM frequently.</p></li></ol><p><u>A bit about caches</u></p><ul><li><p>Temporal Locality: Let&rsquo;s say the processor needs acess to a datum value that&rsquo;s not in any of the caches yet and hence needs to be fetched from the memory. When this datum is fetched from the memory for the processor to be able to use it, it&rsquo;s also loaded into the cache. This serves what&rsquo;s known as &ldquo;temporal locality&rdquo; which, in essence, means that the processor has the tendency to use the same datum value again in near future and hence it&rsquo;s valuable to store it in the cache.</p></li><li><p>Spatial Locality: The way data is loaded in the cache(s) is in the granularity of what&rsquo;s knows as <u>cache lines</u>. This means it&rsquo;s not just one particular datum that&rsquo;s loaded in the cache, but a whole &ldquo;cache line&rdquo; of contiguous data values is loaded along with it. So, let&rsquo;s say the cache line size for a particular processor is 128 bytes (which is the case for my machine - Apple M4), that&rsquo;s equivalent to loading a line of 4 fp32 floats. Consequently, cache eviction, which refers to removing certain data from the cache in order to feed in new data, also happens in cache lines. The question here is why we would do this. It&rsquo;s because this serves &ldquo;spatial locality&rdquo; which states that the processor is likely to use in future the data values near the current datum it&rsquo;s required to use.</p></li></ul><p>Let&rsquo;s see this in action:</p><p>Understanding caches and the way they work is really important for performance engineering. One example of that is here.</p><ol start=4><li>SIMD units:</li></ol><h3 id=gpu>GPU<a hidden class=anchor aria-hidden=true href=#gpu>#</a></h3><p>From the same <a href=https://cvw.cac.cornell.edu/gpu-architecture/gpu-characteristics/design>source</a>, here&rsquo;s what a GPU chip looks like:</p><p><img loading=lazy src=gpu-chip.png#center alt="A GPU chip"></p><p>As can be seen, the major chip area is now occupied by the green boxes which are the components where the computation takes place. But what&rsquo;s also worth noting is that each green box is now much more smaller than 1 single ALU in the CPU core &ndash; this actually reflects the real scenario that a single of these units on the GPU is much much less powerful than a single ALU and hence has a much longer latency.</p><p>The L1 caches and the control occupy much lesser chip area.</p><h2 id=memory-bus>Memory Bus<a hidden class=anchor aria-hidden=true href=#memory-bus>#</a></h2><h2 id=memory-bandwidth>Memory Bandwidth<a hidden class=anchor aria-hidden=true href=#memory-bandwidth>#</a></h2><h3 id=why-cant-cpus-just-have-a-higher-memory-bandwidth>Why can&rsquo;t CPUs just have a higher memory bandwidth?<a hidden class=anchor aria-hidden=true href=#why-cant-cpus-just-have-a-higher-memory-bandwidth>#</a></h3><h2 id=why-parallelization>Why parallelization?<a hidden class=anchor aria-hidden=true href=#why-parallelization>#</a></h2><p>Until 2004, Moore&rsquo;s law, that states that the number of transistors on an integrated circuit doubles roughly every two years, was full in action. This along with Dennard scaling led to faster chips, with increased clock rates at a constant power and cost requirement, coming in about every 18 months or so. And hence, optimization of sequential programs, though useful wasn&rsquo;t really the focus as every two years or so, the new hardware guaranteed better performance for the exact same (unoptimized sequential code) anyways.</p><p>What changed then?
While Moore&rsquo;s law kept allowing for more transistors per chip (smaller in size and more in number), Dennard scaling broke. Meaning we could no longer get increased clock rates on a single core due to issues like charge leakage, heat dissipation etc. and hence hardware engineers couldn&rsquo;t fit more transistors onto a single core which further meant programmers could no longer depend on the hardware in order to get speedups to their programs. What the hardware industry then transitioned to is the multicore cpu chips we know today. This required the programmers to write parallel code so as to be able to continue enjoying speedups moving beyond a single cpu core. In short, moving forward the only way to get better performance is parallelism as from a hardware pove, single core performance gains have already maxed out.</p></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/computer-architecture-optimization-parallel-processing/>Computer Architecture, Optimization, Parallel Processing</a></li></ul><nav class=paginav><a class=prev href=http://localhost:1313/blog/matmul-cpu/><span class=title>¬´ Prev</span><br><span>[WIP] Optimizing matmul on CPU</span>
</a><a class=next href=http://localhost:1313/blog/moes/><span class=title>Next ¬ª</span><br><span>Switch Transformer - Sparse Routed Networks/MoEs</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2026 <a href=http://localhost:1313/>Srishti Gureja</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}}</script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js defer></script></body></html>