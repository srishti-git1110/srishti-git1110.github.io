---
title: About
draft: false
---
Hi there! My name is Srishti.
I am a Machine Learning Engineer and Researcher broadly interested in two research areas:
- Alignment of Language Models (For example: While, in theory, SFT teaches the models to lie and RLHF helps get around this by virtue of Reward Models, how well do RMs work **specifically** for this purpose?)
- Techniques for efficient training of and inference from Language Models (Towards this interest, I am also learning GPU Programming these days)

## Work
- I am fortunate to be working with [Alex Havrilla](https://dahoas.github.io/) on LLM Alignment.

- My full time job is as an ML Engineer at an Indian startup where I work on many things ML + software engineering including fine-tuning language models for focussed use cases, building evaluation and training pipelines etc.

- I am also working with [Eleuther AI](https://www.eleuther.ai/) towards a project aimed at understanding Conditional Pre-training of LMs at scale as a way to achieve better alignment. The rationale here is that rather than first learning and then unlearning unwanted behaviour via techniques like RLHF, how much it benefits at scale to learn aligned behaviour right from the pre-training stage.

- In the past, I have worked at [Translated](https://translated.com/welcome) where I had a lot of fun working on the intersection of LLMs, DP, FL, PEFT for the [EU Data Tools for Heart Project](https://www.datatools4heart.eu/).

- I was also one of the 10 fellows that were selected to be a part of [Pi School](https://picampus-school.com/) where I worked on using many traditional and neural NLP techniques to automate an end to end document processing and analysis pipeline for a Berlin-based startup, Briink.

- I started teaching myself Machine learning in late 2021 using online courses. In the Jan of 2022, I worked on evaluating the robutness of BERT based models for the task of biomedical entity linking - we got this published as a workshop paper @ NeurIPS '22.

This is also the time when I got deeply interested in the internal workings of PyTorch which led me to studying and exploring more of the library an outcome of which is something I cherish - I was awarded by The Linux Foundation and The PyTorch Foundation with one of the 12 [PyTorch Contributor Awards 2023](https://pytorch.org/ecosystem/contributor-awards-2023).